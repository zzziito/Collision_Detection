{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "folder_path = '../dataset'\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "class_files = {'cls': [], 'ctc': [], 'fre': []}\n",
    "for file in files:\n",
    "    if 'cls' in file:\n",
    "        class_files['cls'].append(file)\n",
    "    elif 'ctc' in file:\n",
    "        class_files['ctc'].append(file)\n",
    "    elif 'fre' in file:\n",
    "        class_files['fre'].append(file)\n",
    "        \n",
    "\n",
    "def extract_joint_from_filename(filename):\n",
    "    parts = filename.split('-')\n",
    "    if parts[1].startswith('joint'):\n",
    "        joint_number = parts[2].split('.')[0]\n",
    "        return joint_number\n",
    "    return None\n",
    "\n",
    "def load_and_combine_files(file_list, folder_path):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.columns = ['Data' for _ in df.columns]\n",
    "        \n",
    "        joint_number = extract_joint_from_filename(file)\n",
    "        df['joint_number'] = joint_number\n",
    "        \n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "cls_data = load_and_combine_files(class_files['cls'], folder_path)\n",
    "ctc_data = load_and_combine_files(class_files['ctc'], folder_path)\n",
    "fre_data = load_and_combine_files(class_files['fre'], folder_path)\n",
    "\n",
    "cls_data['label'] = 0  \n",
    "ctc_data['label'] = 1  \n",
    "fre_data['label'] = 2  \n",
    "\n",
    "combined_data = pd.concat(\n",
    "    [cls_data.iloc[1:], ctc_data.iloc[1:], fre_data.iloc[1:]],\n",
    "    ignore_index=True, axis=0\n",
    ")\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    df['joint_number'] = df['joint_number'].astype(int)\n",
    "    \n",
    "    # 클래스 레이블과 조인트 위치 추출\n",
    "    labels = df['label'].values\n",
    "    joints = df['joint_number'].values\n",
    "\n",
    "    signals = df.drop(['label', 'joint_number'], axis=1).values\n",
    "    signals = signals.astype(float)  \n",
    "\n",
    "    return torch.tensor(signals, dtype=torch.float32), torch.tensor(labels, dtype=torch.int32), torch.tensor(joints, dtype=torch.int32)\n",
    "\n",
    "signals, labels, joints = prepare_dataset(combined_data)\n",
    "\n",
    "dataset = TensorDataset(signals, labels, joints)\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.7) # adjust the value  \n",
    "test_size = total_size - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
